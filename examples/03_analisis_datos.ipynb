{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga y Analisis de Datos\n",
    "\n",
    "Este notebook muestra como obtener distribuciones de datasets y analizar sus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import httpx\n",
    "import io\n",
    "\n",
    "from server import get_distributions, search_datasets\n",
    "\n",
    "def get_fn(tool):\n",
    "    return tool.fn if hasattr(tool, 'fn') else tool\n",
    "\n",
    "# Configurar pandas para mostrar mas columnas\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtener Distribuciones de un Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero buscar un dataset con CSV\n",
    "async def buscar_dataset_csv():\n",
    "    fn = get_fn(search_datasets)\n",
    "    result = await fn(title=\"poblacion\", format=\"csv\")\n",
    "    return json.loads(result)\n",
    "\n",
    "datasets = await buscar_dataset_csv()\n",
    "print(f\"Datasets encontrados: {datasets.get('total_in_page')}\")\n",
    "\n",
    "if datasets.get('datasets'):\n",
    "    primer_dataset = datasets['datasets'][0]\n",
    "    print(f\"\\nDataset: {primer_dataset.get('title')}\")\n",
    "    print(f\"URI: {primer_dataset.get('uri')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener distribuciones con preview\n",
    "async def obtener_distribuciones(dataset_uri):\n",
    "    dataset_id = dataset_uri.split('/')[-1]\n",
    "    fn = get_fn(get_distributions)\n",
    "    result = await fn(dataset_id=dataset_id, include_preview=True, preview_rows=5)\n",
    "    return json.loads(result)\n",
    "\n",
    "if datasets.get('datasets'):\n",
    "    distribuciones = await obtener_distribuciones(primer_dataset.get('uri'))\n",
    "    print(f\"Distribuciones: {distribuciones.get('total_in_page')}\")\n",
    "    \n",
    "    for dist in distribuciones.get('distributions', []):\n",
    "        print(f\"\\n- Formato: {dist.get('format')}\")\n",
    "        print(f\"  URL: {dist.get('access_url', '')[:80]}...\")\n",
    "        if dist.get('preview'):\n",
    "            preview = dist['preview']\n",
    "            print(f\"  Columnas: {preview.get('columns', [])}\")\n",
    "            print(f\"  Filas totales: {preview.get('total_rows')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descargar y Cargar CSV en Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def descargar_csv(url):\n",
    "    \"\"\"Descargar CSV y cargar en DataFrame.\"\"\"\n",
    "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "        response = await client.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Detectar encoding\n",
    "        content = response.content\n",
    "        try:\n",
    "            text = content.decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            text = content.decode('latin-1')\n",
    "        \n",
    "        # Detectar delimitador\n",
    "        first_line = text.split('\\n')[0]\n",
    "        delimiter = ';' if first_line.count(';') > first_line.count(',') else ','\n",
    "        \n",
    "        return pd.read_csv(io.StringIO(text), delimiter=delimiter)\n",
    "\n",
    "# Buscar una distribucion CSV y descargarla\n",
    "if 'distribuciones' in dir():\n",
    "    for dist in distribuciones.get('distributions', []):\n",
    "        if dist.get('format') and 'csv' in str(dist.get('format')).lower():\n",
    "            url = dist.get('access_url')\n",
    "            if url:\n",
    "                try:\n",
    "                    df = await descargar_csv(url)\n",
    "                    print(f\"Datos descargados: {len(df)} filas, {len(df.columns)} columnas\")\n",
    "                    display(df.head())\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error descargando: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analisis Basico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in dir() and not df.empty:\n",
    "    print(\"Informacion del DataFrame:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nEstadisticas:\")\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in dir() and not df.empty:\n",
    "    # Buscar columnas numericas para graficar\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    \n",
    "    if numeric_cols:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        df[numeric_cols[0]].hist(ax=ax, bins=30)\n",
    "        ax.set_title(f'Distribucion de {numeric_cols[0]}')\n",
    "        ax.set_xlabel(numeric_cols[0])\n",
    "        ax.set_ylabel('Frecuencia')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ejemplo Completo: Analizar Datos de Poblacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ejemplo_poblacion():\n",
    "    \"\"\"Ejemplo completo de busqueda y analisis.\"\"\"\n",
    "    \n",
    "    # 1. Buscar datasets de poblacion con CSV\n",
    "    fn = get_fn(search_datasets)\n",
    "    result = await fn(title=\"censo\", format=\"csv\")\n",
    "    datasets = json.loads(result)\n",
    "    \n",
    "    if not datasets.get('datasets'):\n",
    "        print(\"No se encontraron datasets\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Encontrados {len(datasets['datasets'])} datasets\")\n",
    "    \n",
    "    # 2. Obtener distribuciones del primero\n",
    "    dataset = datasets['datasets'][0]\n",
    "    dataset_id = dataset['uri'].split('/')[-1]\n",
    "    \n",
    "    fn_dist = get_fn(get_distributions)\n",
    "    dist_result = await fn_dist(dataset_id=dataset_id)\n",
    "    distribuciones = json.loads(dist_result)\n",
    "    \n",
    "    # 3. Encontrar CSV\n",
    "    csv_url = None\n",
    "    for dist in distribuciones.get('distributions', []):\n",
    "        fmt = str(dist.get('format', '')).lower()\n",
    "        if 'csv' in fmt:\n",
    "            csv_url = dist.get('access_url')\n",
    "            break\n",
    "    \n",
    "    if not csv_url:\n",
    "        print(\"No se encontro CSV\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Descargar y analizar\n",
    "    df = await descargar_csv(csv_url)\n",
    "    print(f\"\\nDataset: {dataset.get('title')}\")\n",
    "    print(f\"Filas: {len(df)}, Columnas: {len(df.columns)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "try:\n",
    "    df_poblacion = await ejemplo_poblacion()\n",
    "    if df_poblacion is not None:\n",
    "        display(df_poblacion.head(10))\n",
    "except Exception as e:\n",
    "    print(f\"Error en ejemplo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siguiente: Integraciones\n",
    "\n",
    "En el siguiente notebook veremos como usar las integraciones con INE, AEMET y BOE.\n",
    "\n",
    "[04_integraciones.ipynb](04_integraciones.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
